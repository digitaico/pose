{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c97b36e-abfa-45f7-a41b-b7f9a23daf9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 16:39:32.856020: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743284372.881739  366134 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743284372.888714  366134 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743284372.912149  366134 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743284372.912192  366134 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743284372.912197  366134 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743284372.912200  366134 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-29 16:39:32.919623: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/jea/.local/lib/python3.11/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/jea/.local/lib/python3.11/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/jea/.local/lib/python3.11/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/jea/.local/lib/python3.11/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import argparse\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "735a38eb-bfeb-455e-a920-5e9c806ffe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoseAnalyzer:\n",
    "    def __init__(self):\n",
    "        # inicia mediapipe pose\n",
    "        self.mp_pose = mp.solutions.pose\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.mp_drawing_styles = mp.solutions_drawing_styles\n",
    "        self.pose = self.mp_pose.Pose(\n",
    "            static_image_mode=False,\n",
    "            model_complexity=2,\n",
    "            enable_segmentation=False,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "\n",
    "        # Define colores\n",
    "        self.colors = {\n",
    "            \"red\":(0,0,255),\n",
    "            \"green\":(0,255,0),\n",
    "            \"blue\":(255,0,0),\n",
    "            \"yellow\":(0,255,255),\n",
    "            \"purple\":(255,0,255),\n",
    "            \"white\":(255,255,255)\n",
    "        }\n",
    "\n",
    "        # accumulator: almacenar posiciones previas para tracking\n",
    "        self.prev_positions = {}\n",
    "        self.stride_distances = []\n",
    "        self.step_heights = []   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8301f844-204d-496c-88cd-67ff8682a121",
   "metadata": {},
   "outputs": [],
   "source": [
    " def calculate_angle(self, a, b, c):\n",
    "        \"\"\" calcular angulo en grados entre tres puntos \"\"\"\n",
    "        if not all(p.visibility > 0.5 for p in  [a,b,c]):\n",
    "            return None\n",
    "\n",
    "        a_coords = np.array([a.x, a.y])\n",
    "        b_coords = np.array([b.x, b.y])\n",
    "        c_coords = np.array([c.x, c.y])\n",
    "\n",
    "        ba = a_coords - b_coords\n",
    "        bc = c_coords - b_coords\n",
    "\n",
    "        cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np,linalg.norm(bc))\n",
    "        angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "\n",
    "        return np.degrees(angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef271343-15d8-4acf-967d-ec4f86a42936",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " def calculate_distance(self, a, b):\n",
    "        \"\"\" Distancia entre dos puntos \"\"\"\n",
    "        if not all(p.visibility > 0.5 for p in [a,b]):\n",
    "            return None\n",
    "\n",
    "        return math.sqrt((b.x - a.x)**2 + (b.y - a.y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b1e74a3-a290-4a9a-a9ab-da327108cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_horizontality(self, a, b):\n",
    "        \"\"\"Calculate horizontality (angle from horizontal in degrees)\"\"\"\n",
    "        if not all(p.visibility > 0.5 for p in [a, b]):\n",
    "            return None\n",
    "            \n",
    "        dx = b.x - a.x\n",
    "        dy = b.y - a.y\n",
    "        angle = math.degrees(math.atan2(dy, dx))\n",
    "        return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14184173-9409-4709-8294-5bac3d277b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vertical_lift(self, ankle, knee, hip, prev_ankle_y=None):\n",
    "        \"\"\"Calculate how much a leg is lifted\"\"\"\n",
    "        if not all(p.visibility > 0.5 for p in [ankle, knee, hip]):\n",
    "            return None, None\n",
    "            \n",
    "        # Current height relative to hip\n",
    "        current_lift = hip.y - ankle.y\n",
    "        \n",
    "        # Change in height from previous frame\n",
    "        lift_change = None\n",
    "        if prev_ankle_y is not None:\n",
    "            lift_change = prev_ankle_y - ankle.y\n",
    "            \n",
    "        return current_lift, lift_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8a609b0-a627-4ebc-bc7e-dc18001ab381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stride(self, left_ankle, right_ankle, frame_height):\n",
    "        \"\"\"Calculate stride distance between steps\"\"\"\n",
    "        if not all(p.visibility > 0.5 for p in [left_ankle, right_ankle]):\n",
    "            return None\n",
    "            \n",
    "        # Convert to pixel coordinates\n",
    "        left_pos = (int(left_ankle.x * frame_height), int(left_ankle.y * frame_height))\n",
    "        right_pos = (int(right_ankle.x * frame_height), int(right_ankle.y * frame_height))\n",
    "        \n",
    "        # Store current positions\n",
    "        current_positions = {\n",
    "            \"left_ankle\": left_pos,\n",
    "            \"right_ankle\": right_pos\n",
    "        }\n",
    "        \n",
    "        # Calculate stride if we have previous positions\n",
    "        stride = None\n",
    "        if \"left_ankle\" in self.prev_positions and \"right_ankle\" in self.prev_positions:\n",
    "            # Check which foot moved (the one with larger displacement)\n",
    "            left_disp = np.linalg.norm(np.array(left_pos) - np.array(self.prev_positions[\"left_ankle\"]))\n",
    "            right_disp = np.linalg.norm(np.array(right_pos) - np.array(self.prev_positions[\"right_ankle\"]))\n",
    "            \n",
    "            if max(left_disp, right_disp) > 5:  # Threshold to detect actual step\n",
    "                stride = max(left_disp, right_disp)\n",
    "                if stride > 5:  # Reasonable stride detected\n",
    "                    self.stride_distances.append(stride)\n",
    "        \n",
    "        # Update previous positions\n",
    "        self.prev_positions = current_positions\n",
    "        return stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e33683ee-ec8f-48f2-9fa2-135ea5aa27f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(self, input_video, output_video=None):\n",
    "        if output_video is None:\n",
    "            # Create output filename by adding \"_analyzed\" before extension\n",
    "            name_parts = input_video.rsplit('.', 1)\n",
    "            output_video = f\"{name_parts[0]}_analyzed.{name_parts[1]}\"\n",
    "        \n",
    "        # Open the video file\n",
    "        cap = cv2.VideoCapture(input_video)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video {input_video}\")\n",
    "            return\n",
    "        \n",
    "        # Get video properties\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        # Create video writer\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video, fourcc, fps, (frame_width, frame_height))\n",
    "        \n",
    "        # Process frames\n",
    "        prev_ankle_y = {\"left\": None, \"right\": None}\n",
    "        \n",
    "        for _ in tqdm(range(total_frames), desc=\"Processing frames\"):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Convert to RGB for MediaPipe\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Process the frame with MediaPipe Pose\n",
    "            results = self.pose.process(rgb_frame)\n",
    "            \n",
    "            if results.pose_landmarks:\n",
    "                # Draw the pose landmarks\n",
    "                self.mp_drawing.draw_landmarks(\n",
    "                    frame,\n",
    "                    results.pose_landmarks,\n",
    "                    self.mp_pose.POSE_CONNECTIONS,\n",
    "                    landmark_drawing_spec=self.mp_drawing_styles.get_default_pose_landmarks_style()\n",
    "                )\n",
    "                \n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "                \n",
    "                # Extract key points\n",
    "                left_shoulder = landmarks[self.mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "                right_shoulder = landmarks[self.mp_pose.PoseLandmark.RIGHT_SHOULDER.value]\n",
    "                left_hip = landmarks[self.mp_pose.PoseLandmark.LEFT_HIP.value]\n",
    "                right_hip = landmarks[self.mp_pose.PoseLandmark.RIGHT_HIP.value]\n",
    "                left_knee = landmarks[self.mp_pose.PoseLandmark.LEFT_KNEE.value]\n",
    "                right_knee = landmarks[self.mp_pose.PoseLandmark.RIGHT_KNEE.value]\n",
    "                left_ankle = landmarks[self.mp_pose.PoseLandmark.LEFT_ANKLE.value]\n",
    "                right_ankle = landmarks[self.mp_pose.PoseLandmark.RIGHT_ANKLE.value]\n",
    "                \n",
    "                # 1. Calculate shoulder horizontality\n",
    "                shoulder_angle = self.check_horizontality(left_shoulder, right_shoulder)\n",
    "                if shoulder_angle is not None:\n",
    "                    # Draw shoulder line\n",
    "                    cv2.line(\n",
    "                        frame, \n",
    "                        (int(left_shoulder.x * frame_width), int(left_shoulder.y * frame_height)),\n",
    "                        (int(right_shoulder.x * frame_width), int(right_shoulder.y * frame_height)),\n",
    "                        self.colors[\"blue\"], \n",
    "                        2\n",
    "                    )\n",
    "                    # Add shoulder horizontality info\n",
    "                    shoulder_text = f\"Shoulder angle: {shoulder_angle:.1f}°\"\n",
    "                    cv2.putText(\n",
    "                        frame, \n",
    "                        shoulder_text,\n",
    "                        (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.7, \n",
    "                        self.colors[\"white\"], \n",
    "                        2\n",
    "                    )\n",
    "                \n",
    "                # 2. Calculate hip horizontality\n",
    "                hip_angle = self.check_horizontality(left_hip, right_hip)\n",
    "                if hip_angle is not None:\n",
    "                    # Draw hip line\n",
    "                    cv2.line(\n",
    "                        frame, \n",
    "                        (int(left_hip.x * frame_width), int(left_hip.y * frame_height)),\n",
    "                        (int(right_hip.x * frame_width), int(right_hip.y * frame_height)),\n",
    "                        self.colors[\"green\"], \n",
    "                        2\n",
    "                    )\n",
    "                    # Add hip horizontality info\n",
    "                    hip_text = f\"Hip angle: {hip_angle:.1f}°\"\n",
    "                    cv2.putText(\n",
    "                        frame, \n",
    "                        hip_text,\n",
    "                        (10, 60), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.7, \n",
    "                        self.colors[\"white\"], \n",
    "                        2\n",
    "                    )\n",
    "                \n",
    "                # 3. Calculate leg lift for left leg\n",
    "                left_lift, left_lift_change = self.calculate_vertical_lift(\n",
    "                    left_ankle, left_knee, left_hip, prev_ankle_y[\"left\"]\n",
    "                )\n",
    "                if left_lift is not None:\n",
    "                    # Update previous ankle position\n",
    "                    prev_ankle_y[\"left\"] = left_ankle.y\n",
    "                    # Normalize lift to frame height\n",
    "                    normalized_lift = left_lift * frame_height\n",
    "                    if normalized_lift > 0:\n",
    "                        self.step_heights.append(normalized_lift)\n",
    "                    # Add left leg lift info\n",
    "                    left_lift_text = f\"Left leg lift: {normalized_lift:.1f}px\"\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        left_lift_text,\n",
    "                        (10, 90),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.7,\n",
    "                        self.colors[\"yellow\"],\n",
    "                        2\n",
    "                    )\n",
    "                \n",
    "                # 4. Calculate leg lift for right leg\n",
    "                right_lift, right_lift_change = self.calculate_vertical_lift(\n",
    "                    right_ankle, right_knee, right_hip, prev_ankle_y[\"right\"]\n",
    "                )\n",
    "                if right_lift is not None:\n",
    "                    # Update previous ankle position\n",
    "                    prev_ankle_y[\"right\"] = right_ankle.y\n",
    "                    # Normalize lift to frame height\n",
    "                    normalized_lift = right_lift * frame_height\n",
    "                    if normalized_lift > 0:\n",
    "                        self.step_heights.append(normalized_lift)\n",
    "                    # Add right leg lift info\n",
    "                    right_lift_text = f\"Right leg lift: {normalized_lift:.1f}px\"\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        right_lift_text,\n",
    "                        (10, 120),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.7,\n",
    "                        self.colors[\"yellow\"],\n",
    "                        2\n",
    "                    )\n",
    "                \n",
    "                # 5. Calculate stride\n",
    "                stride = self.calculate_stride(left_ankle, right_ankle, frame_height)\n",
    "                if stride is not None and stride > 5:  # Reasonable stride\n",
    "                    # Add stride info\n",
    "                    stride_text = f\"Stride: {stride:.1f}px\"\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        stride_text,\n",
    "                        (10, 150),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.7,\n",
    "                        self.colors[\"purple\"],\n",
    "                        2\n",
    "                    )\n",
    "                \n",
    "                # 6. Display average values\n",
    "                if len(self.stride_distances) > 0:\n",
    "                    avg_stride = sum(self.stride_distances) / len(self.stride_distances)\n",
    "                    avg_stride_text = f\"Avg stride: {avg_stride:.1f}px\"\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        avg_stride_text,\n",
    "                        (frame_width - 250, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.7,\n",
    "                        self.colors[\"white\"],\n",
    "                        2\n",
    "                    )\n",
    "                \n",
    "                if len(self.step_heights) > 0:\n",
    "                    avg_height = sum(self.step_heights) / len(self.step_heights)\n",
    "                    avg_height_text = f\"Avg leg lift: {avg_height:.1f}px\"\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        avg_height_text,\n",
    "                        (frame_width - 250, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.7,\n",
    "                        self.colors[\"white\"],\n",
    "                        2\n",
    "                    )\n",
    "            \n",
    "            # Write the frame to output video\n",
    "            out.write(frame)\n",
    "        \n",
    "        # Release resources\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        print(f\"Analysis complete. Output saved to {output_video}\")\n",
    "        \n",
    "        # Return summary stats\n",
    "        summary = {\n",
    "            \"avg_stride\": sum(self.stride_distances) / len(self.stride_distances) if self.stride_distances else 0,\n",
    "            \"max_stride\": max(self.stride_distances) if self.stride_distances else 0,\n",
    "            \"avg_leg_lift\": sum(self.step_heights) / len(self.step_heights) if self.step_heights else 0,\n",
    "            \"max_leg_lift\": max(self.step_heights) if self.step_heights else 0\n",
    "        }\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89502faf-66aa-4ede-8fe4-1044984916b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--output OUTPUT] input_video\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Analyze pose in a video')\n",
    "    parser.add_argument('input_video', type=str, help='Path to input video file')\n",
    "    parser.add_argument('--output', type=str, help='Path to output video file (optional)')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    analyzer = PoseAnalyzer()\n",
    "    summary = analyzer.process_video(args.input_video, args.output)\n",
    "    \n",
    "    print(\"\\nAnalysis Summary:\")\n",
    "    print(f\"Average Stride Distance: {summary['avg_stride']:.2f} pixels\")\n",
    "    print(f\"Maximum Stride Distance: {summary['max_stride']:.2f} pixels\")\n",
    "    print(f\"Average Leg Lift: {summary['avg_leg_lift']:.2f} pixels\")\n",
    "    print(f\"Maximum Leg Lift: {summary['max_leg_lift']:.2f} pixels\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
